# Apache Parquet Implementation

é€™å€‹ç›®éŒ„åŒ…å«äº†å®Œæ•´çš„Apache Parquetå¯¦ç¾ï¼Œå±•ç¤ºäº†å¦‚ä½•åœ¨Goä¸­ä½¿ç”¨Parqueté€²è¡Œé«˜æ•ˆçš„åˆ—å¼æ•¸æ“šå­˜å„²å’Œè™•ç†ã€‚Parquetæ˜¯ä¸€ç¨®é–‹æºçš„åˆ—å¼å­˜å„²æ ¼å¼ï¼Œç‰¹åˆ¥é©åˆå¤§æ•¸æ“šåˆ†æå’ŒETLå·¥ä½œæµã€‚

## ğŸ“ ç›®éŒ„çµæ§‹

```
pkg/sdl/parquet/
â”œâ”€â”€ models.go              # Parquetæ•¸æ“šæ¨¡å‹å®šç¾©
â”œâ”€â”€ simple_manager.go      # åŸºæœ¬Parquetæ–‡ä»¶æ“ä½œç®¡ç†å™¨
â”œâ”€â”€ workflows.go           # æ•¸æ“šè™•ç†å·¥ä½œæµç¤ºä¾‹
â”œâ”€â”€ *_test.go             # æ¸¬è©¦æ–‡ä»¶
â”œâ”€â”€ benchmark_test.go      # æ€§èƒ½æ¸¬è©¦
â”œâ”€â”€ workflows_test.go      # å·¥ä½œæµæ¸¬è©¦
â””â”€â”€ README.md             # æœ¬æ–‡ä»¶
```

## ğŸš€ å¿«é€Ÿé–‹å§‹

### ç’°å¢ƒè¦æ±‚

1. **Go 1.19+**
2. **ä¾è³´åº«**: 
   ```bash
   go get github.com/segmentio/parquet-go
   ```

### åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹

```go
package main

import (
    "fmt"
    "log"
    "time"
    
    "go-transport-prac/pkg/sdl/parquet"
)

func main() {
    // å‰µå»ºç®¡ç†å™¨
    manager := parquet.NewSimpleManager("data/parquet")
    
    // å‰µå»ºç¤ºä¾‹æ•¸æ“š
    users := []parquet.User{
        {
            ID:     1,
            Email:  "john@example.com",
            Name:   "John Doe",
            Status: "active",
            Profile: &parquet.Profile{
                FirstName: "John",
                LastName:  "Doe",
                Phone:     "+1-555-0123",
                Address: &parquet.Address{
                    Street:     "123 Main St",
                    City:       "New York",
                    State:      "NY",
                    PostalCode: "10001",
                    Country:    "USA",
                },
                Interests: []string{"technology", "sports"},
                Metadata: map[string]string{
                    "source": "manual",
                    "type":   "premium",
                },
            },
            CreatedAt: time.Now(),
            UpdatedAt: time.Now(),
        },
    }
    
    // å¯«å…¥Parquetæ–‡ä»¶
    err := manager.WriteUsers("users.parquet", users)
    if err != nil {
        log.Fatal(err)
    }
    fmt.Println("âœ“ Data written to Parquet file")
    
    // è®€å–Parquetæ–‡ä»¶
    readUsers, err := manager.ReadUsers("users.parquet")
    if err != nil {
        log.Fatal(err)
    }
    fmt.Printf("âœ“ Read %d users from Parquet file\n", len(readUsers))
    
    // ç²å–æ–‡ä»¶ä¿¡æ¯
    info, err := manager.GetBasicFileInfo("users.parquet")
    if err != nil {
        log.Fatal(err)
    }
    fmt.Printf("File info: %d rows, %d bytes\n", info.NumRows, info.FileSize)
}
```

## ğŸ§ª é‹è¡Œæ¸¬è©¦

### é‹è¡Œæ‰€æœ‰æ¸¬è©¦

```bash
cd /path/to/go-transport-prac
go test ./pkg/sdl/parquet -v
```

### é‹è¡Œç‰¹å®šæ¸¬è©¦é¡å‹

```bash
# åŸºæœ¬æ“ä½œæ¸¬è©¦
go test ./pkg/sdl/parquet -v -run TestSimpleParquetOperations

# ç”¢å“æ“ä½œæ¸¬è©¦
go test ./pkg/sdl/parquet -v -run TestProductOperations

# ETLå·¥ä½œæµæ¸¬è©¦
go test ./pkg/sdl/parquet -v -run TestETLWorkflow

# æ‰¹è™•ç†æ¸¬è©¦
go test ./pkg/sdl/parquet -v -run TestBatchProcessing

# æ•¸æ“šè³ªé‡æ¸¬è©¦
go test ./pkg/sdl/parquet -v -run TestDataQualityCalculation
```

### æŸ¥çœ‹æ¸¬è©¦è¦†è“‹ç‡

```bash
go test ./pkg/sdl/parquet -cover
```

è©³ç´°è¦†è“‹ç‡å ±å‘Šï¼š

```bash
go test ./pkg/sdl/parquet -coverprofile=coverage.out
go tool cover -html=coverage.out
```

## ğŸ“Š æ€§èƒ½æ¸¬è©¦

### é‹è¡Œæ‰€æœ‰åŸºæº–æ¸¬è©¦

```bash
go test -bench=. -benchmem ./pkg/sdl/parquet
```

### é‹è¡Œç‰¹å®šåŸºæº–æ¸¬è©¦

```bash
# Parquet vs JSON åºåˆ—åŒ–æ¯”è¼ƒ
go test -bench=BenchmarkParquet.*Serialization -benchmem ./pkg/sdl/parquet
go test -bench=BenchmarkJSON.*Serialization -benchmem ./pkg/sdl/parquet

# ååºåˆ—åŒ–æ€§èƒ½
go test -bench=BenchmarkParquet.*Deserialization -benchmem ./pkg/sdl/parquet
go test -bench=BenchmarkJSON.*Deserialization -benchmem ./pkg/sdl/parquet

# å¤§å°æ¯”è¼ƒ
go test -bench=BenchmarkParquetVsJSONSize -benchmem ./pkg/sdl/parquet

# å®Œæ•´é€±æœŸæ¸¬è©¦
go test -bench=BenchmarkParquet.*FullCycle -benchmem ./pkg/sdl/parquet
go test -bench=BenchmarkJSON.*FullCycle -benchmem ./pkg/sdl/parquet

# ä¸åŒæ•¸æ“šé›†å¤§å°æ¸¬è©¦
go test -bench=BenchmarkParquet.*Dataset -benchmem ./pkg/sdl/parquet

# å…§å­˜ä½¿ç”¨æ¸¬è©¦
go test -bench=BenchmarkParquetMemoryUsage -benchmem ./pkg/sdl/parquet
```

### åŸºæº–æ¸¬è©¦çµæœè§£è®€

```
BenchmarkParquetUserSerialization-16    1206    917806 ns/op   6985921 B/op   4798 allocs/op
```

- `1206`: åŸ·è¡Œæ¬¡æ•¸
- `917806 ns/op`: æ¯æ¬¡æ“ä½œå¹³å‡è€—æ™‚ (ç´ç§’)
- `6985921 B/op`: æ¯æ¬¡æ“ä½œå¹³å‡å…§å­˜åˆ†é… (å­—ç¯€)
- `4798 allocs/op`: æ¯æ¬¡æ“ä½œå¹³å‡å…§å­˜åˆ†é…æ¬¡æ•¸
- `-16`: ä½¿ç”¨çš„CPUæ ¸å¿ƒæ•¸

### æ€§èƒ½åŸºæº–çµæœç¸½çµ

åŸºæ–¼æˆ‘å€‘çš„åŸºæº–æ¸¬è©¦çµæœï¼š

| æŒ‡æ¨™ | Parquet | JSON | Parquetå„ªå‹¢ |
|------|---------|------|-------------|
| åºåˆ—åŒ–é€Ÿåº¦ | 918Î¼s | 824Î¼s | JSONå¿« 11% |
| ååºåˆ—åŒ–é€Ÿåº¦ | 1525Î¼s | 2630Î¼s | **Parquetå¿« 72%** |
| æ•¸æ“šå¤§å° | 174KB | 456KB | **Parquetå° 62%** |
| å®Œæ•´é€±æœŸ | 604Î¼s | 337Î¼s | JSONå¿« 79% |

**çµè«–**: Parquetåœ¨æ•¸æ“šå¤§å°å’Œååºåˆ—åŒ–æ€§èƒ½ä¸Šå…·æœ‰é¡¯è‘—å„ªå‹¢ï¼Œç‰¹åˆ¥é©åˆå¤§æ•¸æ“šå ´æ™¯ã€‚

## ğŸ”„ æ•¸æ“šè™•ç†å·¥ä½œæµ

### ETLå·¥ä½œæµç¤ºä¾‹

```go
// å‰µå»ºæ•¸æ“šè™•ç†ç®¡é“
pipeline := parquet.NewDataPipeline("data/pipeline")

// é‹è¡Œå®Œæ•´çš„ETLå·¥ä½œæµ
err := pipeline.RunETLWorkflow()
if err != nil {
    log.Fatal(err)
}

// æ¸…ç†å·¥ä½œæµæ–‡ä»¶
defer pipeline.CleanupWorkflow()
```

### æ‰¹è™•ç†å·¥ä½œæµ

```go
// é‹è¡Œæ‰¹è™•ç†å·¥ä½œæµ
err := pipeline.RunBatchProcessing()
if err != nil {
    log.Fatal(err)
}
```

### åˆ†æå·¥ä½œæµ

```go
// é‹è¡Œåˆ†æå·¥ä½œæµ
err := pipeline.RunAnalyticsWorkflow()
if err != nil {
    log.Fatal(err)
}
```

## ğŸ“ˆ Parquetç‰¹é»èˆ‡å„ªå‹¢

### æ ¸å¿ƒå„ªå‹¢

1. **åˆ—å¼å­˜å„²**: é«˜æ•ˆçš„æ•¸æ“šå£“ç¸®å’ŒæŸ¥è©¢æ€§èƒ½
2. **Schemaæ¼”é€²**: æ”¯æŒæ·»åŠ ã€åˆ é™¤å­—æ®µè€Œä¸å½±éŸ¿å…¼å®¹æ€§
3. **å£“ç¸®æ•ˆç‡**: ç›¸æ¯”JSONç¯€çœç´„62%çš„å­˜å„²ç©ºé–“
4. **è·¨å¹³å°**: æ”¯æŒå¤šç¨®ç·¨ç¨‹èªè¨€å’Œæ•¸æ“šè™•ç†æ¡†æ¶
5. **å…ƒæ•¸æ“šè±å¯Œ**: åŒ…å«è©³ç´°çš„Schemaå’Œçµ±è¨ˆä¿¡æ¯

### é©ç”¨å ´æ™¯

**å„ªå…ˆé¸æ“‡Parquet:**
- å¤§æ•¸æ“šåˆ†æå’ŒETLç®¡é“
- æ•¸æ“šå€‰åº«å’Œæ•¸æ“šæ¹–å­˜å„²
- æ‰¹è™•ç†å’ŒOLAPæŸ¥è©¢
- é•·æœŸæ•¸æ“šæ­¸æª”
- éœ€è¦é«˜å£“ç¸®æ¯”çš„å ´æ™¯
- åˆ—å¼æŸ¥è©¢å’Œèšåˆæ“ä½œ

**å¯è€ƒæ…®å…¶ä»–æ ¼å¼:**
- å¯¦æ™‚æ•¸æ“šäº¤æ› (è€ƒæ…®JSON)
- ç°¡å–®çš„éµå€¼å­˜å„² (è€ƒæ…®JSON/MessagePack)
- æµå¼è™•ç† (è€ƒæ…®Avro)
- å‰ç«¯æ‡‰ç”¨ (è€ƒæ…®JSON)

### æ€§èƒ½ç‰¹å¾µ

| æ–¹é¢ | Parquetè¡¨ç¾ | èªªæ˜ |
|------|-------------|------|
| è®€å–æ€§èƒ½ | â­â­â­â­â­ | åˆ—å¼å­˜å„²ï¼Œæ”¯æŒè¬‚è©ä¸‹æ¨ |
| å¯«å…¥æ€§èƒ½ | â­â­â­â­ | éœ€è¦æ§‹å»ºåˆ—å¼çµæ§‹ï¼Œç¨æ…¢æ–¼è¡Œå¼ |
| å£“ç¸®ç‡ | â­â­â­â­â­ | å„ªç§€çš„å£“ç¸®ç®—æ³•æ”¯æŒ |
| Schemaéˆæ´»æ€§ | â­â­â­â­ | æ”¯æŒè¤‡é›œåµŒå¥—çµæ§‹ |
| è·¨èªè¨€æ”¯æŒ | â­â­â­â­â­ | å»£æ³›çš„ç”Ÿæ…‹ç³»çµ±æ”¯æŒ |

## ğŸ› ï¸ æ•¸æ“šæ¨¡å‹

### æ”¯æŒçš„æ•¸æ“šé¡å‹

```go
// åŸºæœ¬æ•¸æ“šé¡å‹
type User struct {
    ID        int64     `parquet:"id"`           // 64ä½æ•´æ•¸
    Email     string    `parquet:"email"`        // UTF-8å­—ç¬¦ä¸²
    Name      string    `parquet:"name"`         
    Status    string    `parquet:"status"`       
    Profile   *Profile  `parquet:"profile"`      // åµŒå¥—çµæ§‹
    CreatedAt time.Time `parquet:"created_at"`   // æ™‚é–“æˆ³
    UpdatedAt time.Time `parquet:"updated_at"`   
}

// åµŒå¥—çµæ§‹
type Profile struct {
    FirstName string            `parquet:"first_name"`
    LastName  string            `parquet:"last_name"`
    Phone     string            `parquet:"phone,optional"`     // å¯é¸å­—æ®µ
    Address   *Address          `parquet:"address,optional"`   // å¯é¸åµŒå¥—çµæ§‹
    Interests []string          `parquet:"interests"`          // å­—ç¬¦ä¸²æ•¸çµ„
    Metadata  map[string]string `parquet:"metadata"`           // éµå€¼å°
}

// è¤‡é›œæ•¸æ“šé¡å‹ç¤ºä¾‹
type Product struct {
    ID            int64                 `parquet:"id"`
    Price         *Price                `parquet:"price"`          // åµŒå¥—çµæ§‹
    Categories    []string              `parquet:"categories"`     // æ•¸çµ„
    Specifications map[string]string   `parquet:"specifications"` // Map
    Inventory     *Inventory            `parquet:"inventory"`      // å¦ä¸€å€‹åµŒå¥—çµæ§‹
}
```

### Parquetæ¨™ç±¤èªªæ˜

- `parquet:"field_name"`: æŒ‡å®šå­—æ®µå
- `parquet:"field_name,optional"`: å¯é¸å­—æ®µ
- æ”¯æŒçš„Goé¡å‹: `int64`, `int32`, `string`, `bool`, `float32`, `float64`, `time.Time`
- æ”¯æŒè¤‡é›œé¡å‹: `struct`, `slice`, `map`

## ğŸ’¡ æœ€ä½³å¯¦è¸

### Schemaè¨­è¨ˆ

1. **å­—æ®µå‘½å**: ä½¿ç”¨snake_caseå‘½åç´„å®š
2. **å¯é¸å­—æ®µ**: ç‚ºå¯èƒ½ç¼ºå¤±çš„å­—æ®µæ·»åŠ `optional`æ¨™ç±¤
3. **åµŒå¥—çµæ§‹**: åˆç†ä½¿ç”¨åµŒå¥—çµæ§‹çµ„ç¹”ç›¸é—œæ•¸æ“š
4. **æ•¸æ“šé¡å‹**: é¸æ“‡åˆé©çš„æ•¸æ“šé¡å‹ä»¥å„ªåŒ–å­˜å„²å’Œæ€§èƒ½

### æ€§èƒ½å„ªåŒ–

1. **æ‰¹é‡æ“ä½œ**: ä¸€æ¬¡è™•ç†å¤šæ¢è¨˜éŒ„è€Œä¸æ˜¯é€æ¢è™•ç†
2. **å…§å­˜ç®¡ç†**: å°å¤§æ•¸æ“šé›†ä½¿ç”¨æµå¼è™•ç†
3. **å£“ç¸®ç®—æ³•**: æ ¹æ“šæ•¸æ“šç‰¹å¾µé¸æ“‡åˆé©çš„å£“ç¸®ç®—æ³•
4. **æ–‡ä»¶å¤§å°**: ä¿æŒåˆç†çš„æ–‡ä»¶å¤§å° (é€šå¸¸128MB-1GB)

### éŒ¯èª¤è™•ç†

```go
// è‰¯å¥½çš„éŒ¯èª¤è™•ç†ç¤ºä¾‹
func processParquetFile(filename string) error {
    manager := parquet.NewSimpleManager("data")
    
    users, err := manager.ReadUsers(filename)
    if err != nil {
        return fmt.Errorf("failed to read parquet file %s: %w", filename, err)
    }
    
    if len(users) == 0 {
        return fmt.Errorf("no users found in file %s", filename)
    }
    
    // è™•ç†æ•¸æ“š...
    
    return nil
}
```

## ğŸ”§ å·¥ä½œæµé›†æˆ

### ETLç®¡é“

```go
// 1. Extract (æå–)
rawData, err := extractFromDatabase()
if err != nil {
    return err
}

// 2. Transform (è½‰æ›)
cleanData := transformAndValidate(rawData)

// 3. Load (åŠ è¼‰)
err = manager.WriteUsers("processed_users.parquet", cleanData)
if err != nil {
    return err
}
```

### æ‰¹è™•ç†

```go
// è™•ç†å¤§æ•¸æ“šé›†çš„æ‰¹æ¬¡
batchSize := 1000
for i := 0; i < len(allUsers); i += batchSize {
    end := i + batchSize
    if end > len(allUsers) {
        end = len(allUsers)
    }
    
    batch := allUsers[i:end]
    filename := fmt.Sprintf("batch_%d.parquet", i/batchSize)
    
    err := manager.WriteUsers(filename, batch)
    if err != nil {
        return fmt.Errorf("failed to write batch %d: %w", i/batchSize, err)
    }
}
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

1. **æ¨™ç±¤èªæ³•éŒ¯èª¤**
   ```
   éŒ¯èª¤: `parquet:"id,int64"`
   æ­£ç¢º: `parquet:"id"`
   ```

2. **å…§å­˜ä¸è¶³**
   ```go
   // å°å¤§æ–‡ä»¶ä½¿ç”¨æµå¼è™•ç†è€Œä¸æ˜¯ä¸€æ¬¡æ€§åŠ è¼‰
   // è€ƒæ…®åˆ†æ‰¹è™•ç†å¤§æ•¸æ“šé›†
   ```

3. **å­—æ®µé¡å‹ä¸åŒ¹é…**
   ```
   ç¢ºä¿Goçµæ§‹é«”å­—æ®µé¡å‹èˆ‡Parquet schemaåŒ¹é…
   ```

4. **æ–‡ä»¶æ¬Šé™å•é¡Œ**
   ```bash
   # ç¢ºä¿æœ‰è®€å¯«æ¬Šé™
   chmod 755 data/parquet/
   ```

### èª¿è©¦æŠ€å·§

```go
// ç²å–è©³ç´°æ–‡ä»¶ä¿¡æ¯
info, err := manager.GetBasicFileInfo("test.parquet")
if err != nil {
    log.Printf("File info error: %v", err)
} else {
    log.Printf("File: %d rows, %d bytes, %d fields", 
        info.NumRows, info.FileSize, len(info.Schema.Fields()))
}

// åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶
files, err := manager.ListFiles()
if err != nil {
    log.Printf("List files error: %v", err)
} else {
    log.Printf("Available files: %v", files)
}
```

## ğŸ“š ç›¸é—œè³‡æº

- [Apache Parquetå®˜æ–¹æ–‡æª”](https://parquet.apache.org/)
- [Go Parquetåº«æ–‡æª”](https://github.com/segmentio/parquet-go)
- [Parquetæ ¼å¼è¦ç¯„](https://github.com/apache/parquet-format)
- [åˆ—å¼å­˜å„²ä»‹ç´¹](https://en.wikipedia.org/wiki/Column-oriented_DBMS)

## ğŸ”„ èˆ‡å…¶ä»–æ ¼å¼å°æ¯”

| ç‰¹æ€§ | Parquet | JSON | Avro | Protocol Buffers |
|------|---------|------|------|------------------|
| å­˜å„²æ•ˆç‡ | â­â­â­â­â­ | â­â­ | â­â­â­â­ | â­â­â­â­ |
| æŸ¥è©¢æ€§èƒ½ | â­â­â­â­â­ | â­â­ | â­â­â­ | â­â­â­ |
| Schemaæ¼”é€² | â­â­â­â­ | â­â­ | â­â­â­â­â­ | â­â­â­â­ |
| äººé¡å¯è®€ | â­ | â­â­â­â­â­ | â­ | â­ |
| è·¨èªè¨€æ”¯æŒ | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| é©ç”¨å ´æ™¯ | åˆ†æã€æ­¸æª” | Webã€API | æµè™•ç† | å¾®æœå‹™é€šä¿¡ |

æ¯ç¨®æ ¼å¼éƒ½æœ‰å…¶æœ€é©åˆçš„ä½¿ç”¨å ´æ™¯ï¼Œé¸æ“‡æ™‚æ‡‰æ ¹æ“šå…·é«”éœ€æ±‚è€ƒæ…®æ€§èƒ½ã€å…¼å®¹æ€§å’Œé–‹ç™¼ä¾¿åˆ©æ€§ç­‰å› ç´ ã€‚